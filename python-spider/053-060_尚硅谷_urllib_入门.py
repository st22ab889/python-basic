
# æœ¬æ•™ç¨‹æ¥è‡ª "å°šç¡…è°·Pythonçˆ¬è™«æ•™ç¨‹å°ç™½é›¶åŸºç¡€é€Ÿé€šï¼ˆå«pythonåŸºç¡€+çˆ¬è™«æ¡ˆä¾‹ï¼‰" : https://www.bilibili.com/video/BV1Db4y1m7Ho

'''
æ–‡ä»¶ååƒä¸‡ä¸è¦è·Ÿè¦å¯¼å…¥çš„æŠ¥åŒ…åä¸€æ ·. form  "076_å°šç¡…è°·_çˆ¬è™«_è§£æ_bs4çˆ¬å–æ˜Ÿå·´å…‹æ•°æ®"  "09:00"
'''

# 052_å°šç¡…è°·_çˆ¬è™«_çˆ¬è™«ç›¸å…³æ¦‚å¿µä»‹ç»
'''
çˆ¬è™«æ ¸å¿ƒ:
    çˆ¬å–ç½‘é¡µ
    è§£ææ•°æ®
    éš¾ç‚¹: çˆ¬è™«å’Œåçˆ¬è™«ä¹‹é—´çš„åšå¼ˆ
çˆ¬è™«çš„ç”¨é€”:
    æ•°æ®åˆ†æ/äººå·¥æ•°æ®é›†
    ç¤¾äº¤å¦‚æ¡ˆä»¶å†·å¯åŠ¨
    èˆ†æƒ…åˆ†æ
    ç«äº‰å¯¹æ‰‹ç›‘æ§
'''

import urllib.request

# 053_å°šç¡…è°·_çˆ¬è™«_urllib_åŸºæœ¬ä½¿ç”¨
# æ¡ˆåˆ—ï¼šä½¿ç”¨ urllib è·å–ç™¾åº¦é¦–é¡µçš„æºç (urllib æ˜¯ python è‡ªå¸¦çš„åº“)
url = 'http://www.baidu.com'

# æ¨¡æ‹Ÿæµè§ˆå™¨å‘æœåŠ¡å™¨å‘é€è¯·æ±‚
response = urllib.request.urlopen(url)

# read æ–¹æ³•è¿”å›çš„æ˜¯å­—èŠ‚å½¢å¼çš„äºŒè¿›åˆ¶æ•°æ®(æ§åˆ¶å°æ‰“å°çš„æ˜¯bå¼€å¤´çš„æ•°æ®, å¦‚: b'<!DOC....')ï¼Œè¿›è¡Œç¼–ç åä¼šè¯»å‡ºåŸå†…å®¹
content = response.read().decode('utf-8')

# print(content)


# 054_å°šç¡…è°·_çˆ¬è™«_urllib_1ä¸ªç±»å‹å’Œ6ä¸ªæ–¹æ³•

# response ç±»å‹æ˜¯ <class 'http.client.HTTPResponse'>
print(type(response))

# å¯¹äºæ•´ä¸ªå†…å®¹, read æ˜¯ä¸€ä¸ªå­—èŠ‚ä¸€ä¸ªå­—èŠ‚è¯». å¦‚æœå†™ä¸º read(5) è¡¨ç¤ºåªè¯»5è¿™ä¸ªæ–‡æ¡£çš„å‰5ä¸ªå­—èŠ‚
content = response.read()

# è¯»å–ä¸€è¡Œ
content = response.readline()

# æ¯è¡Œä¾æ¬¡è¯»ï¼Œç›´åˆ°è¯»å®Œ
content = response.readlines()

# æ‹¿ http çŠ¶æ€ç 
response.getcode()

# æ‹¿ url åœ°å€
response.geturl()

# get header
response.getheaders()


# 055_å°šç¡…è°·_çˆ¬è™«_urllib_ä¸‹è½½
url_page = 'http://www.baidu.com/s?wd=beauty'
# ç›´æ¥å†™æ–‡ä»¶å"baidu.html", æ–‡ä»¶å°†ä¿å­˜åœ¨æ­¤pythonæ–‡ä»¶åŒæ ·çš„ç›®å½•ä¸‹
# urllib.request.urlretrieve(url_page, 'baidu.html')  # ä¹Ÿå¯ä»¥å†™ä¸º urllib.request.urlretrieve(url = url_page, 'baidu.html')
# åŠ ä¸Šç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„å¯ä»¥ä¿å­˜åœ¨æŒ‡å®šçš„ç›®å½•ä¸‹
# urllib.request.urlretrieve(url_page, './055_urlretrieve/baidu.html')

# 056_å°šç¡…è°·_çˆ¬è™«_urllib_è¯·æ±‚å¯¹è±¡çš„å®šåˆ¶
# urlçš„ç»„æˆ: åè®® + ä¸»æœºåœ°å€(åŸŸå) + ç«¯å£å· + è·¯å¾„ + å‚æ•° + é”šç‚¹(æ¯”å¦‚ç”¨åœ¨ç™¾åº¦æ£€ç´¢)
url = 'https://www.baidu.com'
response = urllib.request.urlopen(url)
content = response.read().decode('utf8')
# è¿™é‡Œæ‰“å°å‡ºæ¥çš„å†…å®¹å¾ˆå°‘ï¼Œå› ä¸ºç½‘ç«™åçˆ¬
# print(content)
'''
åçˆ¬æ‰‹æ®µä¸€: UA(User-Agent)
User-Agent è¯·æ±‚å¤´ä½¿æœåŠ¡å™¨èƒ½å¤Ÿè¯†åˆ«å®¢æˆ·ç«¯çš„æ“ä½œç³»ç»ŸåŠç‰ˆæœ¬ã€CPUç±»å‹ã€æµè§ˆå™¨ç‰ˆæœ¬ã€æµè§ˆå™¨å†…æ ¸ã€æµè§ˆå™¨æ¸²æŸ“å¼•æ“ã€æµè§ˆå™¨è¯­è¨€ã€æµè§ˆå™¨æ’ä»¶ç­‰
ç½‘ä¸Šæœ UA å¤§å…¨å¯ä»¥æœç´¢åˆ°å¾ˆå¤šï¼Œä¹Ÿå¯ä»¥ä»æµè§ˆå™¨çš„httpè¯·æ±‚çš„headerä¸­çœ‹åˆ°
'''
headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 Edg/133.0.0.0'
}
request = urllib.request.Request(url=url, headers=headers)
response = urllib.request.urlopen(request)
# print(response.read().decode('utf8'))



# 057_å°šç¡…è°·_çˆ¬è™«_urllib_getè¯·æ±‚çš„quoteæ–¹æ³•
'''
ASCIIğŸ : 127ä¸ªå­—ç¬¦, åŒ…å«å¤§å°å†™è‹±æ–‡å­—æ¯ã€æ•°å­—å’Œå…¶å®ƒä¸€äº›ç¬¦å·, å 1ä¸ªå­—èŠ‚
GB2312: ä¸­å›½åˆ¶å®šçš„, å ä¸¤ä¸ªå­—èŠ‚
Unicode: è‹å“¦æœ‰çš„è¯­è¨€ç»Ÿä¸€åˆ°ä¸€å¥—ç¼–ç ä¸­ï¼Œè§£å†³ä¹±ç é—®é¢˜ã€‚ç°åœ¨æ“ä½œç³»ç»Ÿå’Œå¤§å¤šæ•°ç¼–ç¨‹è¯­è¨€éƒ½ç›´æ¥æ”¯æŒ Unicode
'''
# "%E7%89%8C%E7%A5%9E" å°±æ˜¯ "ç‰Œç¥" çš„ Unicode ç , è¿™é‡Œåªæ£€ç´¢ Unicode ç ï¼Œ å¦‚æœç›´æ¥å†™ä¸­æ–‡ï¼Œè¿è¡Œç¨‹åºçš„æ—¶å€™ä¼šæŠ¥é”™
url = "https://www.baidu.com/s?wd=%E7%89%8C%E7%A5%9E"

import  urllib.parse
url_base = "https://www.baidu.com/s?wd="
param = urllib.parse.quote("ç‰Œç¥")
url_base += param
print(url_base)


# 058_å°šç¡…è°·_çˆ¬è™«_urllib_getè¯·æ±‚çš„urlencodeæ–¹æ³•

data = {
    'language': 'ç‰Œç¥',
    'do': 'çˆ¬è™«'
}
# urlencode é€‚åˆå¤šå‚æ•°ä¸€èµ·è½¬Unicode
result = urllib.parse.urlencode(data)
# print(result)


# 059_å°šç¡…è°·_çˆ¬è™«_urllib_postè¯·æ±‚ç™¾åº¦ç¿»è¯‘
url = 'https://fanyi.baidu.com/sug'

headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36 Edg/133.0.0.0'
}

data = {
    'kw': 'ç¼–ç¨‹è¯­è¨€'
}

# ç›´æ¥ä½¿ç”¨è¿™ä¸ª form_data ä¼šæŠ¥é”™"TypeError: POST data should be bytes, an iterable of bytes, or a file object. It cannot be of type str."
form_data = urllib.parse.urlencode(data)
# print(type(form_data))        # ç»“æœæ˜¯:   <class 'str'>
# print(form_data)              # ç»“æœæ˜¯:  kw=%E7%89%8C%E7%A5%9E
form_data = urllib.parse.urlencode(data).encode('utf-8')
# print(form_data)              # ç»“æœæ˜¯:  b'kw=%E7%89%8C%E7%A5%9E'

request = urllib.request.Request(url, form_data, headers)
response = urllib.request.urlopen(request)
content = response.read().decode('utf-8')

import json
obj = json.loads(content)
print(obj)

'''
post è¯·æ±‚çš„å‚æ•°å¿…é¡»è¿›è¡Œ urlencode ç¼–ç , ç„¶åå†è¿›è¡Œ encode ç¼–ç 
'''


# 060_å°šç¡…è°·_çˆ¬è™«_urllib_postè¯·æ±‚ç™¾åº¦ç¿»è¯‘ä¹‹è¯¦ç»†ç¼–è¯‘

# æ­¤æ¡ˆä¾‹æ²¡æœ‰æˆåŠŸï¼Œå› ä¸ºæœ€æ–°çš„æ¥å£åŠ å…¥äº†åçˆ¬æœºåˆ¶
url = 'https://fanyi.baidu.com/ait/text/translate'

headers = {
    # åœ¨å†™çˆ¬è™«çš„æ—¶å€™ä¸€å®šè¦æ³¨æ„: æ¥æ”¶çš„ç¼–ç ç±»å‹ä¸€å®šè¦ä¸º"utf-8"
    # 'Accept-Encoding': 'gzip, deflate, br, zstd',
    'Accept-Language': 'zh-CN,zh;q=0.9',
    'Acs-Token': '1740110795800_1740155349937_ID6y/ZrAC/F/OvvO7oRLEEMbQBTmwPxbp7nNlE9kmDCwpIRIM/trR6cVGx54soEANYlQ+M+nHI1/mqtCCh9dQQesTxmGzN5R5Ihb3Q+Bbpq2TQ3gPqEAgHLgK1Cd3QDc6iKxbR0BPP/WcTXuE2QsY92EKRHP8V1RWpb3cU7SrEsLGr3b4r8j3o1D95kjBr4wHd5cSN6XyvWBw6jmzqG188a7zc/vVvnhdZ7dglW0Ruq5NxXqwLrQ7szQ0Eg/PyB2e38u/CEW6TBuC0/Fst1myTezYl0yOGkv4nujwP6o3wtZsiwxOSJp5x8tpIK/ZvaxfrU+kHVQ9Wc4H7ZPj9JgN3pluRhfiB4EkSnDib3oyb6+RXL1wKGMMSAr1ZovwkSDnWoNdjg4X35lk6EU/yzN9nvGad3AKfNkwkHqIqVchmExZqMb7wrJ86cgOLNFADC0s4Pgg7Hj3MHbt1jDQ4JdicCbAm7vDwi6V6MF+Tjgqnw=',
    'Connection': 'keep-alive',
    'Content-Length': '159',
    'Content-Type': 'application/json',
    # å¾ˆå¤šç½‘ç«™ä½¿ç”¨ Cookie æ¥ä½œä¸ºåçˆ¬è™«çš„ header, ä½†ä¹Ÿå¯èƒ½æ·»åŠ å…¶å®ƒheaderæ¥åçˆ¬è™«
    'Cookie': 'BIDUPSID=1BB0DE7D95079F542F5446FBFAB04B99; PSTM=1721828140; BAIDUID=6C9457CD722A89C1FE19A05843F36A73:FG=1; H_WISE_SIDS_BFESS=60277_61027_61668_61986_62055_62062_61880; MAWEBCUID=web_wiwLDoGvEpPhrKTyPLqoFjxfqyFMjGCYdUsylalWRHuLmEDXzJ; H_WISE_SIDS=60277_61027_61668_61986_62055_62062_61880_62114; ZFY=KKIEV9kYCpBofnOPGRn9dRe5OfcI:A1AJA3YOZ20SLws:C; BAIDUID_BFESS=6C9457CD722A89C1FE19A05843F36A73:FG=1; BA_HECTOR=2g818120a10h2lal8005a00kbosg0c1jrh9e91v; PSINO=6; delPer=0; BDORZ=B490B5EBF6F3CD402E515D22BCDA1598; BCLID=2329470737958916562; BCLID_BFESS=2329470737958916562; BDSFRCVID=V_8OJexroGWIeXOJxWzeEHtYoFweG7bTDYrEOwXPsp3LGJLVvqHuEG0Pts1-dEu-S2OOogKK3gOTH4eX_gt26qgfED4ZSjabVyQatf8g0M5; BDSFRCVID_BFESS=V_8OJexroGWIeXOJxWzeEHtYoFweG7bTDYrEOwXPsp3LGJLVvqHuEG0Pts1-dEu-S2OOogKK3gOTH4eX_gt26qgfED4ZSjabVyQatf8g0M5; H_BDCLCKID_SF=tRAOoC_-tDvDqTrP-trf5DCShUFsLq4OB2Q-XPoO3M3zefnOyR7R24LkyhOk2M5f5mkf3fbgy4op8P3y0bb2DUA1y4vp-Jo7bmTxoUJ2-KDVeh5Gqq-KXU4ebPRiJ-b9Qg-J0xn75--KM4jTbxoUjhI9MxQaLJcIK6nhVn0MBCK0HPonHj_-ej3b3f; H_BDCLCKID_SF_BFESS=tRAOoC_-tDvDqTrP-trf5DCShUFsLq4OB2Q-XPoO3M3zefnOyR7R24LkyhOk2M5f5mkf3fbgy4op8P3y0bb2DUA1y4vp-Jo7bmTxoUJ2-KDVeh5Gqq-KXU4ebPRiJ-b9Qg-J0xn75--KM4jTbxoUjhI9MxQaLJcIK6nhVn0MBCK0HPonHj_-ej3b3f; ab_sr=1.0.1_ZmMxMWY4NjMzMjFlOWEzZGYxMzhlYjg3ZGU5MzZjYTM2ZTk0MjQxOWYwNzA2ODM4NWFhNDNlODRhNjlkMTFhNWUzNjlhMmUyMWRjNDRlNmZhYjM5NTI4ODkyOWNmMzMyMDViOTY3NTRlZDg5OTMyZTIwMGNjMWM3NTNlNWU3YmNiOTg1NTk2NzczNzRhYmQ5Y2ViMjkyOGU2M2VjMTM5ZDZkMjkyNzc4ZTAyZGU5ZjUwYzBkYTA2NzFhZWFmYjhiZTFkMDM5NDQ1MzA0ZGEyMDAxMTc5OGIyOGQ0MTMwYzQ=; H_PS_PSSID=60277_61027_61668_62114_62131_62156_62167_62177_62185_62186_62182_62195_62236_62230_62262; RT="z=1&dm=baidu.com&si=b66e3cad-d2c8-414c-875b-05e7b9e11ae4&ss=m7eyyc36&sl=6&tt=4sz&bcn=https%3A%2F%2Ffclog.baidu.com%2Flog%2Fweirwood%3Ftype%3Dperf&ld=l64n"',
    'Host': 'fanyi.baidu.com',
    'Origin': 'https://fanyi.baidu.com',
    'Referer': 'https://fanyi.baidu.com/mtpe-individual/multimodal?query=this%20is%20a%20bad%20%0Agood%0Abook&lang=en2zh&ext_channel=Aldtype',
    'Sec-Fetch-Dest': 'empty',
    'Sec-Fetch-Mode': 'cors',
    'Sec-Fetch-Site': 'same-origin',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36',
    'accept': 'text/event-stream',
    'sec-ch-ua': '"Not(A:Brand";v="99", "Google Chrome";v="133", "Chromium";v="133"',
    'sec-ch-ua-mobile': '?0',
    'sec-ch-ua-platform': '"Windows"'
}

payload = {
    "query": "this is a nice book",
    "from": "en",
    "to": "zh",
    "reference": "",
    "corpusIds": [],
    "needPhonetic": True,
    "domain": "common"
}

payload = urllib.parse.urlencode(payload).encode('utf-8')
request = urllib.request.Request(url, payload, headers)
response = urllib.request.urlopen(request)
content = response.read().decode('utf-8')
print(content)

'''
å‚è€ƒ deepseek çš„å›ç­”ï¼š
    æé—®: æ²¡æœ‰ç™»å½•åˆ°ç™¾åº¦ï¼Œä¹Ÿæœ‰  Acs-Token è¿™ä¸ªheaderï¼Œå¹¶ä¸”æ¯è®¿é—®ä¸€æ¬¡ï¼Œè¿™ä¸ªå€¼éƒ½ä¼šå˜åŒ–
    å›ç­”: å¦‚æœæœªç™»å½•ç™¾åº¦ï¼Œä½†è¯·æ±‚å¤´ä¸­ä»ç„¶åŒ…å« Acs-Tokenï¼Œå¹¶ä¸”æ¯æ¬¡è®¿é—®æ—¶è¯¥å€¼éƒ½ä¼šå˜åŒ–ï¼Œé‚£ä¹ˆ Acs-Token å¾ˆå¯èƒ½æ˜¯ç™¾åº¦ç”¨äº åçˆ¬è™«æœºåˆ¶ æˆ– ä¼šè¯è·Ÿè¸ª çš„åŠ¨æ€ä»¤ç‰Œã€‚ä»¥ä¸‹æ˜¯å¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ³•ï¼š
          ......
'''
